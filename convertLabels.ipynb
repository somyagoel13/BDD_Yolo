{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc985b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed!\n",
      "Processed 69863 images\n",
      "Generated 69863 label files\n",
      "\n",
      "Object counts by category:\n",
      "  car: 713211\n",
      "  traffic sign: 239686\n",
      "  traffic light: 186117\n",
      "  person: 91349\n",
      "  truck: 29971\n",
      "  bus: 11672\n",
      "  bike: 7210\n",
      "  rider: 4517\n",
      "  motor: 3002\n",
      "  train: 136\n",
      "\n",
      "Created dataset configuration file: /nfs/ECAC_Data/Somya_data/BDD_Data/bdd100k_images_100k/bdd100k/images/100k/bdd100k.yaml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "\n",
    "def convert_bdd_to_yolo(json_file_path, output_dir, image_dir=None):\n",
    "    \"\"\"\n",
    "    Convert BDD100K JSON annotations to YOLO format text files\n",
    "    \n",
    "    Args:\n",
    "        json_file_path (str): Path to the BDD100K JSON annotation file\n",
    "        output_dir (str): Directory to save YOLO format text files\n",
    "        image_dir (str, optional): Directory containing images (for validation)\n",
    "    \"\"\"\n",
    "    # BDD100K class mapping to YOLO class indices\n",
    "    class_dict = {\n",
    "        'bus': 0,\n",
    "        'traffic light': 1,\n",
    "        'traffic sign': 2,\n",
    "        'person': 3,\n",
    "        'bike': 4,\n",
    "        'truck': 5,\n",
    "        'motor': 6,\n",
    "        'car': 7,\n",
    "        'train': 8,\n",
    "        'rider': 9\n",
    "    }\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Load JSON annotations\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "    \n",
    "    # Count statistics\n",
    "    stats = defaultdict(int)\n",
    "    missing_images = []\n",
    "    \n",
    "    # Process each image annotation\n",
    "    for annotation in annotations:\n",
    "        image_name = annotation['name']\n",
    "        image_width = annotation.get('width', 1280)  # Default BDD100K width\n",
    "        image_height = annotation.get('height', 720)  # Default BDD100K height\n",
    "        \n",
    "        # Check if image exists (if image_dir provided)\n",
    "        if image_dir:\n",
    "            image_path = Path(image_dir) / image_name\n",
    "            if not image_path.exists():\n",
    "                missing_images.append(image_name)\n",
    "                continue\n",
    "        \n",
    "        # Prepare YOLO format content\n",
    "        yolo_lines = []\n",
    "        \n",
    "        # Process each label in the image\n",
    "        for label in annotation.get('labels', []):\n",
    "            if 'box2d' not in label:\n",
    "                continue  # Skip non-bounding box annotations\n",
    "                \n",
    "            category = label['category']\n",
    "            if category not in class_dict:\n",
    "                continue  # Skip unknown categories\n",
    "                \n",
    "            # Get bounding box coordinates\n",
    "            box = label['box2d']\n",
    "            x1, y1, x2, y2 = box['x1'], box['y1'], box['x2'], box['y2']\n",
    "            \n",
    "            # Convert to YOLO format (normalized center coordinates and dimensions)\n",
    "            x_center = (x1 + x2) / (2 * image_width)\n",
    "            y_center = (y1 + y2) / (2 * image_height)\n",
    "            width = (x2 - x1) / image_width\n",
    "            height = (y2 - y1) / image_height\n",
    "            \n",
    "            # Ensure values are within [0, 1] range\n",
    "            x_center = max(0, min(1, x_center))\n",
    "            y_center = max(0, min(1, y_center))\n",
    "            width = max(0, min(1, width))\n",
    "            height = max(0, min(1, height))\n",
    "            \n",
    "            # Get class ID\n",
    "            class_id = class_dict[category]\n",
    "            \n",
    "            # Format line for YOLO\n",
    "            yolo_line = f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
    "            yolo_lines.append(yolo_line)\n",
    "            \n",
    "            # Update statistics\n",
    "            stats[category] += 1\n",
    "        \n",
    "        # Write YOLO format file\n",
    "        output_file = output_path / f\"{Path(image_name).stem}.txt\"\n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write(\"\\n\".join(yolo_lines))\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"Conversion completed!\")\n",
    "    print(f\"Processed {len(annotations)} images\")\n",
    "    print(f\"Generated {len(list(output_path.glob('*.txt')))} label files\")\n",
    "    print(\"\\nObject counts by category:\")\n",
    "    for category, count in sorted(stats.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {category}: {count}\")\n",
    "    \n",
    "    if missing_images:\n",
    "        print(f\"\\nWarning: {len(missing_images)} images were missing in the image directory\")\n",
    "        if len(missing_images) < 10:  # Only show a few examples\n",
    "            print(\"Missing images:\", missing_images[:5])\n",
    "            if len(missing_images) > 5:\n",
    "                print(f\"... and {len(missing_images) - 5} more\")\n",
    "\n",
    "def create_dataset_yaml(output_dir, class_dict, train_split=0.8):\n",
    "    \"\"\"\n",
    "    Create a YAML dataset configuration file for YOLO training\n",
    "    \n",
    "    Args:\n",
    "        output_dir (str): Directory where the dataset is stored\n",
    "        class_dict (dict): Dictionary mapping class names to IDs\n",
    "        train_split (float): Proportion of data to use for training\n",
    "    \"\"\"\n",
    "    # Get all image files\n",
    "    image_files = list(Path(output_dir).parent.glob(\"images/*.jpg\")) + \\\n",
    "                 list(Path(output_dir).parent.glob(\"images/*.png\"))\n",
    "    \n",
    "    # Split into train and validation\n",
    "    num_train = int(len(image_files) * train_split)\n",
    "    train_files = image_files[:num_train]\n",
    "    val_files = image_files[num_train:]\n",
    "    \n",
    "    # Write train and validation text files\n",
    "    with open(Path(output_dir).parent / \"train.txt\", \"w\") as f:\n",
    "        for img_path in train_files:\n",
    "            f.write(f\"{img_path}\\n\")\n",
    "    \n",
    "    with open(Path(output_dir).parent / \"val.txt\", \"w\") as f:\n",
    "        for img_path in val_files:\n",
    "            f.write(f\"{img_path}\\n\")\n",
    "    \n",
    "    # Create YAML content\n",
    "    yaml_content = f\"\"\"# BDD100K Dataset YAML\n",
    "path: {Path(output_dir).parent}  # dataset root directory\n",
    "train: train.txt  # train images (relative to 'path')\n",
    "val: val.txt  # val images (relative to 'path')\n",
    "\n",
    "# Classes\n",
    "nc: {len(class_dict)}  # number of classes\n",
    "names: {list(class_dict.keys())}  # class names\n",
    "\"\"\"\n",
    "    \n",
    "    # Write YAML file\n",
    "    yaml_path = Path(output_dir).parent / \"bdd100k.yaml\"\n",
    "    with open(yaml_path, \"w\") as f:\n",
    "        f.write(yaml_content)\n",
    "    \n",
    "    print(f\"\\nCreated dataset configuration file: {yaml_path}\")\n",
    "\n",
    "def main():\n",
    "    #parser = argparse.ArgumentParser(description='Convert BDD100K JSON annotations to YOLO format')\n",
    "    ##parser.add_argument('--json', type=str, required=True, help='Path to BDD100K JSON annotation file')\n",
    "    ##parser.add_argument('--output', type=str, required=True, help='Output directory for YOLO format files')\n",
    "    #parser.add_argument('--image-dir', type=str, help='Directory containing images (for validation)')\n",
    "    #parser.add_argument('--create-yaml', action='store_true', help='Create YAML dataset configuration file')\n",
    "    \n",
    "    #args = parser.parse_args()\n",
    "    \n",
    "    # Class mapping\n",
    "    class_dict = {\n",
    "        'bus': 0,\n",
    "        'traffic light': 1,\n",
    "        'traffic sign': 2,\n",
    "        'person': 3,\n",
    "        'bike': 4,\n",
    "        'truck': 5,\n",
    "        'motor': 6,\n",
    "        'car': 7,\n",
    "        'train': 8,\n",
    "        'rider': 9\n",
    "    }\n",
    "    json = \"/nfs/ECAC_Data/Somya_data/BDD_Data/bdd100k_labels_release/bdd100k/labels/bdd100k_labels_images_train.json\"\n",
    "    #output = \"/nfs/ECAC_Data/Somya_data/BDD_Data/bdd100k_labels_release/bdd100k/labels/yolo_train/\"\n",
    "    image_dir = \"/nfs/ECAC_Data/Somya_data/BDD_Data/bdd100k_images_100k/bdd100k/images/100k/train/\"\n",
    "    output = image_dir\n",
    "    \n",
    "    # Convert annotations\n",
    "    convert_bdd_to_yolo(json, output, image_dir)\n",
    "    \n",
    "    # Create YAML if requested\n",
    "    #if args.create_yaml:\n",
    "    create_dataset_yaml(output, class_dict)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f3d7779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualized 10 images in /nfs/ECAC_Data/Somya_data/BDD_Data/bdd100k_images_100k/bdd100k/images/100k/val_yolo_label/\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "def visualize_yolo_labels(image_dir, label_dir, output_dir, num_samples=10):\n",
    "    \"\"\"\n",
    "    Visualize YOLO labels on images to verify conversion quality\n",
    "    \n",
    "    Args:\n",
    "        image_dir (str): Directory containing images\n",
    "        label_dir (str): Directory containing YOLO format labels\n",
    "        output_dir (str): Output directory for visualized images\n",
    "        num_samples (int): Number of samples to visualize\n",
    "    \"\"\"\n",
    "    # Class mapping for BDD100K\n",
    "    class_dict = {\n",
    "        0: 'bus',\n",
    "        1: 'traffic light',\n",
    "        2: 'traffic sign',\n",
    "        3: 'person',\n",
    "        4: 'bike',\n",
    "        5: 'truck',\n",
    "        6: 'motor',\n",
    "        7: 'car',\n",
    "        8: 'train',\n",
    "        9: 'rider'\n",
    "    }\n",
    "    \n",
    "    # Colors for different classes\n",
    "    colors = [(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) \n",
    "              for _ in range(len(class_dict))]\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = list(Path(image_dir).glob(\"*.jpg\")) + list(Path(image_dir).glob(\"*.png\"))\n",
    "    sampled_files = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "    \n",
    "    # Create output directory\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Process each sampled image\n",
    "    for img_path in sampled_files:\n",
    "        # Load image\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img_h, img_w = img.shape[:2]\n",
    "        \n",
    "        # Load corresponding labels\n",
    "        label_path = Path(label_dir) / f\"{img_path.stem}.txt\"\n",
    "        if not label_path.exists():\n",
    "            continue\n",
    "            \n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "                \n",
    "            class_id = int(parts[0])\n",
    "            x_center, y_center, width, height = map(float, parts[1:5])\n",
    "            \n",
    "            # Convert YOLO format to pixel coordinates\n",
    "            x_center *= img_w\n",
    "            y_center *= img_h\n",
    "            width *= img_w\n",
    "            height *= img_h\n",
    "            \n",
    "            x1 = int(x_center - width / 2)\n",
    "            y1 = int(y_center - height / 2)\n",
    "            x2 = int(x_center + width / 2)\n",
    "            y2 = int(y_center + height / 2)\n",
    "            \n",
    "            # Draw rectangle\n",
    "            color = colors[class_id % len(colors)]\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "            \n",
    "            # Add label\n",
    "            label = class_dict.get(class_id, f\"Class {class_id}\")\n",
    "            cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        \n",
    "        # Save visualized image\n",
    "        output_file = output_path / f\"vis_{img_path.name}\"\n",
    "        cv2.imwrite(str(output_file), img)\n",
    "    \n",
    "    print(f\"Visualized {len(sampled_files)} images in {output_dir}\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    visualize_yolo_labels(\n",
    "        image_dir=\"/nfs/ECAC_Data/Somya_data/BDD_Data/bdd100k_images_100k/bdd100k/images/100k/tra\",\n",
    "        label_dir=\"/nfs/ECAC_Data/Somya_data/BDD_Data/bdd100k_labels_release/bdd100k/labels/yolo_tr/\",\n",
    "        output_dir=\"/nfs/ECAC_Data/Somya_data/BDD_Data/bdd100k_images_100k/bdd100k/images/100k/val_yolo_label/\"\n",
    "    )\n",
    "    \"\"\"\n",
    "    json = \"/nfs/ECAC_Data/Somya_data/BDD_Data/bdd100k_labels_release/bdd100k/labels/bdd100k_labels_images_val.json\"\n",
    "    output = \"/nfs/ECAC_Data/Somya_data/BDD_Data/bdd100k_labels_release/bdd100k/labels/yolo_val/\"\n",
    "    image_dir = \"/nfs/ECAC_Data/Somya_data/BDD_Data/bdd100k_images_100k/bdd100k/images/100k/val/\"\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32048b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
